{"cells":[{"cell_type":"markdown","metadata":{"id":"ueXMU1YCUjsI"},"source":["# Moviepy"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"vm3gClKgUjsU"},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"UK-DCx5hUjsf"},"outputs":[],"source":["# 포즈 감지 모델 초기화\n","mp_pose = mp.solutions.pose\n","pose_video = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.7,\n","                          min_tracking_confidence=0.7)\n","mp_drawing = mp.solutions.drawing_utils"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"UYMcrqmaUjsj"},"outputs":[],"source":["# 포즈 검출 함수\n","def detectPose(image_pose, pose, draw=False, display=False):\n","    \n","    original_image = image_pose.copy()\n","    \n","    image_in_RGB = cv2.cvtColor(image_pose, cv2.COLOR_BGR2RGB)\n","    \n","    resultant = pose.process(image_in_RGB)\n","\n","    if resultant.pose_landmarks and draw:    \n","\n","        mp_drawing.draw_landmarks(image=original_image, landmark_list=resultant.pose_landmarks,\n","                                  connections=mp_pose.POSE_CONNECTIONS,\n","                                  landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255,255,255),\n","                                                                               thickness=3, circle_radius=3),\n","                                  connection_drawing_spec=mp_drawing.DrawingSpec(color=(49,125,237),\n","                                                                               thickness=2, circle_radius=2))\n","\n","    if display:\n","            \n","            plt.figure(figsize=[22,22])\n","            plt.subplot(121);plt.imshow(image_pose[:,:,::-1]);plt.title(\"Input Image\");plt.axis('off');\n","            plt.subplot(122);plt.imshow(original_image[:,:,::-1]);plt.title(\"Pose detected Image\");plt.axis('off');\n","\n","    else:\n","        \n","        return original_image, resultant"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zf2YXz3zUjsp"},"outputs":[],"source":["def norm(data):\n","    data = np.array(data)\n","    x = data.T[0]\n","    y = data.T[1]\n","    z = data.T[2]\n","    x_norm = (x - min(x)) / (max(x) - min(x))\n","    y_norm = (y - min(y)) / (max(y) - min(y))\n","    z_norm = (z - min(z)) / (max(z) - min(z))\n","    \n","    return (x_norm.tolist(), y_norm.tolist(), z_norm.tolist())"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"flQrP2gAUjsv"},"outputs":[],"source":["def link_vector(land):\n","    link_keypoint = [(0, 1),\n","        (1, 3),\n","        (3,\t5),\n","        (5,\t7),\n","        (5,\t9),\n","        (5,\t11),\n","        (1, 13),\n","        (13, 15),\n","        (15, 17),\n","        (17, 19),\n","        (17, 21),\n","        (0, 2),\n","        (2, 4),\n","        (4, 6),\n","        (4, 8),\n","        (4, 10),\n","        (4, 12),\n","        (2, 14),\n","        (14, 16),\n","        (16, 18),\n","        (18, 20),\n","        (18, 22)]\n","    \n","    a = []\n","    for link in link_keypoint:\n","        x = land[0][link[0]] - land[0][link[1]]\n","        y = land[1][link[0]] - land[1][link[1]]\n","        z = land[2][link[0]] - land[2][link[1]]\n","        a.append((x, y, z))\n","    return a"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"q6oSRAs_Ujsz"},"outputs":[],"source":["def angle_vector(land):\n","    \n","    import math\n","    \n","    angle_keypoint=[\n","        (0, 1, 3),\n","        (1, 3, 5),\n","        (3, 5, 9),\n","        (1, 13, 15),\n","        (13, 15, 17),\n","        (15, 17, 19),\n","        (15, 17, 21),\n","        (0, 2, 4),\n","        (2, 4, 6),\n","        (4, 6, 10),\n","        (2, 14, 16),\n","        (14, 16, 18),\n","        (16, 18, 20),\n","        (16, 18, 22)]\n","    \n","    a = []\n","    for angle in angle_keypoint:\n","        x = np.array([land[0][angle[0]] - land[0][angle[1]], land[1][angle[0]] - land[1][angle[1]], land[2][angle[0]] - land[2][angle[1]]])\n","        y = np.array([land[0][angle[1]] - land[0][angle[2]], land[1][angle[1]] - land[1][angle[2]], land[2][angle[1]] - land[2][angle[2]]])\n","        \n","        분자 = np.dot(x, y)\n","        분모 = np.sqrt(x.dot(x)) * np.sqrt(x.dot(x))\n","        try:\n","            a.append(math.acos(분자 / 분모))\n","        except:\n","            a.append(0)\n","    return (a)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"oM7zFuxrUjs8"},"outputs":[],"source":["def pose_feature(link, angle):\n","    산술평균_링크 = [np.mean(link.T[0]), np.mean(link.T[1]), np.mean(link.T[2])]\n","    표준편차_링크 = [np.std(link.T[0]), np.std(link.T[1]), np.std(link.T[2])]\n","    제곱평균_링크 = [np.mean(link.T[0]**2), np.mean(link.T[1]**2), np.mean(link.T[2]**2)]\n","    \n","    산술평균_앵글 = np.mean(angle)\n","    표준편차_앵글 = np.std(angle)\n","    제곱평균_앵글 = np.mean(angle)\n","    \n","    return(산술평균_링크+표준편차_링크+제곱평균_링크+[산술평균_앵글]+[표준편차_앵글]+[제곱평균_앵글])"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"1YU2OEkeUjtA"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Miniconda3\\envs\\kdig\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","c:\\ProgramData\\Miniconda3\\envs\\kdig\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n"]}],"source":["import joblib\n","model = joblib.load('./RandomForest.pkl')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"0pFYpo6MUjtO"},"outputs":[],"source":["def get_sim(target, user):\n","    target_landmarks = target.pose_world_landmarks.landmark\n","    target_lm = [(i.x, i.y, i.z) for num, i in enumerate(target_landmarks) if num not in range(1, 11)]\n","    target_norm = norm(target_lm)\n","    target_link_vector = link_vector(target_norm)\n","    target_angle_vector = angle_vector(target_norm)\n","    \n","    user_landmarks = user.pose_world_landmarks.landmark\n","    user_lm = [(i.x, i.y, i.z) for num, i in enumerate(user_landmarks) if num not in range(1, 11)]\n","    user_norm = norm(user_lm)\n","    user_link_vector = link_vector(user_norm)\n","    user_angle_vector = angle_vector(user_norm)\n","    \n","    link_diff = np.array(target_link_vector) - user_link_vector\n","    angle_diff = np.array(target_angle_vector) - user_angle_vector\n","    feature = pose_feature(link_diff, angle_diff); feature = np.array(feature).reshape(1, -1)\n","    similarity = model.predict_proba(feature)[0][1]\n","    \n","    return similarity"]},{"cell_type":"markdown","metadata":{"id":"2hFCc6esUjtF"},"source":["## BTS - Dynamite"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"SwIQRtEmUjtH"},"outputs":[],"source":["from moviepy.editor import *\n","video_clip = VideoFileClip('./dance/BTS Dynamite_target.mp4')\n","video_len = video_clip.duration\n","video_clip2 = VideoFileClip('./dance/BTS Dynamite_user.mp4').subclip(0.2, video_len+0.2)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"zbaPa8BHUjtJ","outputId":"c38d1c6e-0dea-450d-f968-733713dce5c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["MoviePy - Writing audio in ./target.mp3\n"]},{"name":"stderr","output_type":"stream","text":["                                                                      "]},{"name":"stdout","output_type":"stream","text":["MoviePy - Done.\n"]},{"name":"stderr","output_type":"stream","text":["\r"]}],"source":["audioclip = video_clip.audio\n","audioclip.write_audiofile('./target.mp3')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"dtwSQArIUjtR"},"outputs":[],"source":["w = 640\n","h = 720\n","fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n","out = cv2.VideoWriter('output.avi', fourcc, 1/0.03, (w, h))\n","\n","ss = []\n","text = ''\n","\n","for num, i in enumerate(np.arange(0, video_len, 0.03)):\n","   \n","    img = video_clip.get_frame(i)\n","    img2 = video_clip2.get_frame(i)\n","    \n","    img_taget = cv2.resize(img, (0, 0), fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n","    img_user = cv2.resize(img2, (0, 0), fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n","    \n","    if (num+1) % 20 == 0:\n","        ss_mean = round(np.mean([i*100 for i in ss[num-18:] if i is not None]))\n","        score = ('BAD' if ss_mean <= 30 else 'GOOD' if ss_mean <= 60 else 'PERPECT')\n","        text = f'{score}'\n","\n","    try:\n","        result = detectPose(img_taget, pose_video)[1]\n","        result2 = detectPose(img_user, pose_video)[1]\n","        \n","        similarity = get_sim(result, result2)\n","        ss.append(similarity)\n","\n","        numpy_vertical = np.vstack((img_taget, img_user))\n","        numpy_vertical_concat = np.concatenate((img_taget, img_user), axis=0)\n","        \n","        ver_cv = cv2.cvtColor(numpy_vertical, cv2.COLOR_BGR2RGB)\n","        \n","        cv2.putText(ver_cv,  text, (10, 380), cv2.FONT_HERSHEY_DUPLEX, 2, (199, 114, 255), 2, cv2.LINE_AA)        # BGR\n","        cv2.imshow(\"target\", ver_cv)\n","        \n","    except:\n","        numpy_vertical = np.vstack((img_taget, img_user))\n","        numpy_vertical_concat = np.concatenate((img_taget, img_user), axis=0)\n","        ss.append(None)\n","        \n","        ver_cv = cv2.cvtColor(numpy_vertical, cv2.COLOR_BGR2RGB)\n","        cv2.putText(ver_cv,  text, (10, 380), cv2.FONT_HERSHEY_DUPLEX, 2, (199, 114, 255), 2, cv2.LINE_AA)        # BGR\n","        cv2.imshow(\"target\", ver_cv)\n","\n","    out.write(ver_cv) #프레임 쓰기\n","    \n","    if cv2.waitKey(1) & 0xFF == 27:\n","        break\n","\n","cv2.destroyAllWindows()\n","out.release()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k-DYBcMlUjtS","outputId":"6d974f3c-2e3c-4a33-b37b-d760ae12795e"},"outputs":[{"name":"stdout","output_type":"stream","text":["최종 점수:  41\n","OK\n"]}],"source":["total = round(np.mean(ss)*100)\n","print(\"최종 점수: \", total)\n","\n","if total <= 30:\n","    print(\"FAIL\")\n","elif total <= 40:\n","    print(\"BAD\")\n","elif total <=60:\n","    print(\"OK\")\n","elif total <=70:\n","    print(\"GOOD\")\n","else:\n","    print(\"GREAT\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v4a8p-D0UjtT"},"outputs":[],"source":["w = 640\n","h = 720\n","fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n","out = cv2.VideoWriter('test.avi', fourcc, 1/0.01, (w, h))\n","\n","for i in np.arange(0, 84.2, 0.01):\n","   \n","    img = video_clip.get_frame(i)\n","    img2 = video_clip2.get_frame(i)\n","    \n","    img_taget = cv2.resize(img, (0, 0), fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n","    img_user = cv2.resize(img2, (0, 0), fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n","\n","    numpy_vertical = np.vstack((img_taget, img_user))\n","    numpy_vertical_concat = np.concatenate((img_taget, img_user), axis=0)\n","    \n","    ver_cv = cv2.cvtColor(numpy_vertical, cv2.COLOR_BGR2RGB)\n","    cv2.imshow(\"target\", ver_cv)\n","    out.write(ver_cv) #프레임 쓰기\n","    \n","    if cv2.waitKey(1) & 0xFF == 27:\n","        break\n","\n","cv2.destroyAllWindows()\n","out.release()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ACcNHeeAUjtV","outputId":"2371aab5-c767-45c0-e2a2-481cfbeaffad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Moviepy - Building video new video.mp4.\n","MoviePy - Writing audio in new videoTEMP_MPY_wvf_snd.mp3\n"]},{"name":"stderr","output_type":"stream","text":["                                                                     \r"]},{"name":"stdout","output_type":"stream","text":["MoviePy - Done.\n","Moviepy - Writing video new video.mp4\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Moviepy - Done !\n","Moviepy - video ready new video.mp4\n"]}],"source":["from moviepy.editor import *\n","videoclip = VideoFileClip(\"output.avi\")\n","audioclip = audioclip\n","\n","videoclip.audio = audioclip\n","videoclip.write_videofile(\"new video.mp4\")"]},{"cell_type":"markdown","metadata":{"id":"aM_dgaS-UjtW"},"source":["## I-DLE - TOMBOY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uz4iV_SNUjtX"},"outputs":[],"source":["from moviepy.editor import *\n","video_clip = VideoFileClip('./영상/I-DLE TOMBOY.mp4').subclip(4.3, 83.48)\n","video_clip2 = VideoFileClip('./영상/I-DLE TOMBOY_user.mp4').subclip(0.7, 74.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Js7Y2mxzUjtZ"},"outputs":[],"source":["# 싱크 맞는지 확인\n","for i in np.arange(0, 84.2, 0.03):\n","   \n","    img = video_clip.get_frame(i)\n","    img2 = video_clip2.get_frame(i)\n","    \n","    img_taget = cv2.resize(img, (0, 0), fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n","    img_user = cv2.resize(img2, (0, 0), fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n","\n","    numpy_vertical = np.vstack((img_taget, img_user))\n","    numpy_vertical_concat = np.concatenate((img_taget, img_user), axis=0)\n","    \n","    ver_cv = cv2.cvtColor(numpy_vertical, cv2.COLOR_BGR2RGB)\n","    cv2.imshow(\"target\", ver_cv)\n","        \n","    # out.write(ver_cv) #프레임 쓰기\n","    \n","    if cv2.waitKey(1) & 0xFF == 27:\n","        break\n","\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OagXy0T3Ujtb"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XXMDModrUjtb"},"source":["# 웹캠 녹화"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7YFnNhp2Ujti"},"outputs":[],"source":["import cv2\n","import sys\n","import time\n","# 노트북 웹캠에서 받아오는 영상을 저장하기\n","\n","# 기본 카메라 객체 생성\n","cap = cv2.VideoCapture(0)\n","\n","# 열렸는지 확인\n","if not cap.isOpened():\n","    print(\"Camera open failed!\")\n","    sys.exit()\n","\n","# 웹캠의 속성 값을 받아오기\n","# 정수 형태로 변환하기 위해 round\n","w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps = cap.get(cv2.CAP_PROP_FPS) # 카메라에 따라 값이 정상적, 비정상적\n","\n","if fps ==0 :\n","    fps=30\n","\n","# fourcc 값 받아오기, *는 문자를 풀어쓰는 방식, *'DIVX' == 'D', 'I', 'V', 'X'\n","fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n","\n","# 1프레임과 다음 프레임 사이의 간격 설정\n","delay = round(1000/fps)\n","\n","# 웹캠으로 찰영한 영상을 저장하기\n","# cv2.VideoWriter 객체 생성, 기존에 받아온 속성값 입력\n","out = cv2.VideoWriter('1.avi', fourcc, fps, (w, h))\n","\n","begins = []\n","# 제대로 열렸는지 확인\n","if not out.isOpened():\n","    print('File open failed!')\n","    cap.release()\n","    sys.exit()\n","    \n","# 프레임을 받아와서 저장하기\n","while True:                 # 무한 루프\n","    ret, frame = cap.read() # 카메라의 ret, frame 값 받아오기\n","\n","    if not ret:             #ret이 False면 중지\n","        break\n","    \n","    cv2.putText(frame, text=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())), org=(30, 450), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0,255,0), thickness=2)\n","    cv2.imshow('frame', frame)\n","    begins.append(time.time())\n","    out.write(frame) # 영상 데이터만 저장. 소리는 X\n","    \n","    # print(cap.get(cv2.CAP_PROP_FPS))\n","    if cv2.waitKey(delay) == 27: # esc를 누르면 강제 종료\n","        end = time.time()\n","        break\n","\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"YZIA9r7AUjtj"},"source":["# 카운트다운 효과"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T9LpYDBlUjtj"},"outputs":[],"source":["import cv2\n","import time\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Fu5tzlGUjtk"},"outputs":[],"source":["for i in range(3, 0, -1):\n","    zeros = np.zeros((720, 1280), dtype=np.uint8)\n","    cv2.putText(zeros, str(i), (580, 360), cv2.FONT_HERSHEY_SIMPLEX, 10, (255,255,255), 20, cv2.LINE_AA)\n","    cv2.imshow('test', zeros)\n","    cv2.waitKey(1000)\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z8tC2ZdrUjtl"},"outputs":[],"source":["import cv2\n","\n","# 웹캠 연결\n","cap = cv2.VideoCapture('./영상/I-DLE TOMBOY.mp4')\n","\n","\n","while True:\n","\n","    # 웹캠에서 이미지 읽어옴\n","    ret,img_color = cap.read()\n","\n","    if ret == False:\n","        print('웹캠에서 영상을 읽을 수 없습니다.')\n","        break\n","    \n","    # print(cap.get(cv2.CAP_PROP_POS_FRAMES))\n","    \n","    if cap.get(cv2.CAP_PROP_POS_FRAMES) == 1:\n","        for i in range(3, 0, -1):\n","            zeros = np.zeros((720, 1280), dtype=np.uint8)\n","            cv2.putText(zeros, str(i), (580, 360), cv2.FONT_HERSHEY_SIMPLEX, 10, (255,255,255), 20, cv2.LINE_AA)\n","            cv2.imshow('test', zeros)\n","            cv2.waitKey(1000)\n","            cv2.destroyAllWindows()\n","        \n","    cv2.imshow(\"test\", img_color)\n","\n","\n","    # ESC키 누르면 중지\n","    if cv2.waitKey(1)&0xFF == 27:\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OLXGwSMxUjtl","outputId":"5007458d-4a6d-45a2-dc4f-c3670ec843f0"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["cap.get(cv2.CAP_PROP_POS_FRAMES) == 0"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"동작일치율_녹화.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.7 ('kdig')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"79235f3c426277640c9689d2572c47b913f40843195eeba115616b689febf123"}}},"nbformat":4,"nbformat_minor":0}
